{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Identification of hand movements from electromyographic signals using Machine Learning (Filtered).ipynb","provenance":[],"collapsed_sections":["-w6S7G8n8u3_","gagzTZ0i8u4D","AxzXxV1n8u4I","NmiCy00f8u43","NtE3KhHA8u48","SWwJsgHR8u5A","Kyg1Gw3r8u5I","18JrDJ618u5N","_GUswl288u5S","LyjimEh68u5Y","-9QnNR4X8u5b","p5K7oaw-8u5t","dhKsEzp68u59","V2omIiWc8u6Y","eUuBf8we8u6e","00wHfcn98u6i","6No0NC9Y8u6-","O6CTTgzl8u7O","GzxXkFIVOprm"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"A7LN-Km28u3J"},"source":["# Hand movement classification using EMG signals"]},{"cell_type":"code","metadata":{"id":"2wx5Q0c4Ozg9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1596812427591,"user_tz":300,"elapsed":32171,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"d232059a-d8f5-4788-f3cb-7da57b4e3bc2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oF44MP3cCciW","colab":{},"executionInfo":{"status":"ok","timestamp":1596812431151,"user_tz":300,"elapsed":6971,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}}},"source":["import os\n","\n","# Establishing the current work directory (cwd)\n","thisdir = # PATH where database recordings are saved\n","Files = []\n","# r=root, d=directories, f = files\n","for r, d, f in os.walk(thisdir):\n","    for file in f:\n","        if \".txt\" in file:\n","            Files.append(os.path.join(r, file))\n","filenames = Files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"H5rNHTcf8u3L"},"source":["## Libraries\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AZU7Z8Qa8u3M","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1596812433976,"user_tz":300,"elapsed":8522,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"d3485d76-db2e-4cbb-df04-951c899057f7"},"source":["import seaborn as sn; sn.set() \n","import pandas as pd\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as colors\n","\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from pandas import set_option\n","\n","import scipy.signal as signal\n","from pywt import dwt,Wavelet\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import classification_report\n","\n","from sklearn import preprocessing\n","from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import Lasso\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.cluster import KMeans\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn import decomposition\n","from sklearn import linear_model\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import Lasso\n","from sklearn.svm import SVC\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.cluster import KMeans\n","\n","from scipy.cluster.hierarchy import dendrogram, linkage\n","from scipy.cluster.hierarchy import cophenet\n","from scipy.spatial.distance import pdist\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import mode\n","\n","from keras.layers import Dense\n","import matplotlib.pyplot as plt\n","from pandas import set_option\n","import pandas as pd\n","from keras.models import Sequential\n","import keras.utils\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","import numpy as np \n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sn \n","import keras\n","from keras.layers import Dense, Dropout, Activation\n","from keras.optimizers import SGD\n","from keras.models import model_from_json\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.layers import Embedding\n","from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.pipeline import Pipeline\n","from keras.utils import np_utils\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n","from keras.optimizers import SGD\n","from keras.layers import Dropout\n","from keras.constraints import maxnorm\n","from keras.layers import Dense, Flatten, Conv1D"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lVdQal5j8u3R"},"source":["##  Creating different DataFrames for train, validation and test (raw data)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TxY1bm4m8u3S","colab":{},"executionInfo":{"status":"ok","timestamp":1596812572337,"user_tz":300,"elapsed":38203,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}}},"source":["def resp_frec(w,h,fs):\n","    fig, ax1 = plt.subplots()\n","    ax1.set_title('Digital filter frequency response')\n","    \n","    ax1.plot((w/(np.pi))*(fs/2), 20 * np.log10(abs(h)), 'b')\n","    ax1.set_ylabel('Amplitude [dB]', color='b')\n","    ax1.set_xlabel('Frequency [Hz]')\n","    \n","    ax2 = ax1.twinx()\n","    angles = np.unwrap(np.angle(h))\n","    ax2.plot((w/(np.pi))*(fs/2), angles, 'g')\n","    ax2.set_ylabel('Angle (radians)', color='g')\n","    ax2.grid()\n","    ax2.axis('tight')\n","\n","def Data_separation(filename, plot_filter=False, plot_signal=False):\n","    Data = pd.read_csv(filename, sep=\"\\t\")  # Import .txt file with raw data\n","    Data = Data.drop(columns=\"time\")   # \"time\" column is removed due to some intervals (few miliseconds) are missing and affect\n","                                       # DataFrame indexing \n","\n","    # fs = 1000                       # Filter design, Bandpass 20-180 Hz\n","    # ws1, wp1, wp2, ws2 = 1, 20, 180, 200\n","    # gpass, gstop = 1, 60\n","    # n, Wn = signal.ellipord([wp1,wp2], [ws1,ws2], gpass, gstop, fs=fs, analog=False)\n","    # b, a = signal.ellip(n, gpass, gstop, Wn, btype='bandpass', analog=False,  fs=fs)\n","    # w, h = signal.freqz(b,a)\n","\n","    # fs = 1000                       # Filter design, Bandpass 10-480 Hz\n","    # ws1, wp1, wp2, ws2 = 1, 10, 480, 500\n","    # gpass, gstop = 1, 60\n","    # n, Wn = signal.ellipord([wp1,wp2], [ws1,ws2], gpass, gstop, fs=fs, analog=False)\n","    # b, a = signal.ellip(n, gpass, gstop, Wn, btype='bandpass', analog=False,  fs=fs)\n","    # w, h = signal.freqz(b,a) \n","\n","    # fs = 1000                         # Filter design, Highpass 20 Hz\n","    # gpass, gstop = 1, 60\n","    # wp, ws = (40)/(fs/2), (20)/(fs/2)\n","    # N = len(Data['channel1'])\n","    # f = (fs/2)*np.linspace(0,1,int(N/2))\n","    # b, a = signal.iirdesign(wp, ws, gpass, gstop, analog=False, ftype='butter')\n","    # w, h = signal.freqz(b,a)\n","\n","    if plot_filter: \n","      resp_frec(w, h, fs)\n","      #plt.axvline(wp1, color='r') # Vertical lines at cut-off frequencies\n","      #plt.axvline(wp2, color='r')\n","      #plt.axvline(ws1)\n","      #plt.axvline(ws2)\n","      plt.show()\n","\n","    if plot_signal:\n","      Data['channel1'].plot()\n","      plt.show()\n","      Data['channel1'][9000:10000].plot()\n","      plt.show()\n","\n","    # Data['channel1']= signal.filtfilt(b,a,Data['channel1']) # Applying the filter\n","    # Data['channel2']= signal.filtfilt(b,a,Data['channel2'])\n","    # Data['channel3']= signal.filtfilt(b,a,Data['channel3'])\n","    # Data['channel4']= signal.filtfilt(b,a,Data['channel4'])\n","    # Data['channel5']= signal.filtfilt(b,a,Data['channel5'])\n","    # Data['channel6']= signal.filtfilt(b,a,Data['channel6'])\n","    # Data['channel7']= signal.filtfilt(b,a,Data['channel7'])\n","    # Data['channel8']= signal.filtfilt(b,a,Data['channel8']) \n","\n","    if plot_signal:\n","      Data['channel1'].plot()\n","      plt.show()\n","      Data['channel1'][9000:10000].plot()\n","      plt.show()\n","\n","    g1 = Data[Data['class'] == 1].index.tolist() # Getting the indexes of each gesture \n","    g2 = Data[Data['class'] == 2].index.tolist()\n","    g3 = Data[Data['class'] == 3].index.tolist()\n","    g4 = Data[Data['class'] == 4].index.tolist()\n","    g5 = Data[Data['class'] == 5].index.tolist()\n","    g6 = Data[Data['class'] == 6].index.tolist()\n"," \n","    df1 = Data.iloc[g1]  # Creating a new DataFrame for each gesture\n","    df2 = Data.iloc[g2]\n","    df3 = Data.iloc[g3]\n","    df4 = Data.iloc[g4]\n","    df5 = Data.iloc[g5]\n","    df6 = Data.iloc[g6]\n","    return df1,df2,df3,df4,df5,df6\n","\n","[df1,df2,df3,df4,df5,df6]=Data_separation(filenames[0], plot_filter=False, plot_signal=False)\n","Gesto1=df1\n","Gesto2=df2\n","Gesto3=df3\n","Gesto4=df4\n","Gesto5=df5\n","Gesto6=df6\n","\n","filenames_train=filenames[1:60]\n","\n","for i in range(len(filenames_train)):\n","    [df1,df2,df3,df4,df5,df6]=Data_separation(filenames[i])\n","    Gesto1=Gesto1.append(df1)\n","    Gesto2=Gesto2.append(df2)\n","    Gesto3=Gesto3.append(df3)\n","    Gesto4=Gesto4.append(df4)\n","    Gesto5=Gesto5.append(df5)\n","    Gesto6=Gesto6.append(df6)\n","\n","Traindata=Gesto1\n","Traindata=Traindata.append(Gesto2)\n","Traindata=Traindata.append(Gesto3)\n","Traindata=Traindata.append(Gesto4)\n","Traindata=Traindata.append(Gesto5)\n","Traindata=Traindata.append(Gesto6)       \n","\n","filenames_valid=filenames[60:66]\n","\n","[df1,df2,df3,df4,df5,df6]=Data_separation(filenames_valid[0])\n","Gesto1=df1\n","Gesto2=df2\n","Gesto3=df3\n","Gesto4=df4\n","Gesto5=df5\n","Gesto6=df6\n","\n","for i in range(len(filenames_valid[1:])):\n","    [df1,df2,df3,df4,df5,df6]=Data_separation(filenames[i])\n","    Gesto1=Gesto1.append(df1)\n","    Gesto2=Gesto2.append(df2)\n","    Gesto3=Gesto3.append(df3)\n","    Gesto4=Gesto4.append(df4)\n","    Gesto5=Gesto5.append(df5)\n","    Gesto6=Gesto6.append(df6)\n","\n","Validdata=Gesto1\n","Validdata=Validdata.append(Gesto2)\n","Validdata=Validdata.append(Gesto3)\n","Validdata=Validdata.append(Gesto4)\n","Validdata=Validdata.append(Gesto5)\n","Validdata=Validdata.append(Gesto6)  \n","\n","filenames_test=filenames[66:72]\n","\n","[df1,df2,df3,df4,df5,df6]=Data_separation(filenames_test[0])\n","Gesto1=df1\n","Gesto2=df2\n","Gesto3=df3\n","Gesto4=df4\n","Gesto5=df5\n","Gesto6=df6\n","\n","for i in range(len(filenames_test[1:])):\n","    [df1,df2,df3,df4,df5,df6]=Data_separation(filenames[i])\n","    Gesto1=Gesto1.append(df1)\n","    Gesto2=Gesto2.append(df2)\n","    Gesto3=Gesto3.append(df3)\n","    Gesto4=Gesto4.append(df4)\n","    Gesto5=Gesto5.append(df5)\n","    Gesto6=Gesto6.append(df6)\n","\n","Testdata=Gesto1\n","Testdata=Testdata.append(Gesto2)\n","Testdata=Testdata.append(Gesto3)\n","Testdata=Testdata.append(Gesto4)\n","Testdata=Testdata.append(Gesto5)\n","Testdata=Testdata.append(Gesto6)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sR13OZfv8u3a"},"source":["## Dividing DataFrames into features and label vectors"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L9dLSsSn8u3b","colab":{},"executionInfo":{"status":"ok","timestamp":1596812575686,"user_tz":300,"elapsed":488,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}}},"source":["Labels_train = Traindata['class']\n","Features_train = Traindata[Traindata.columns[0:8]]\n","\n","Labels_valid = Validdata['class']\n","Features_valid = Validdata[Validdata.columns[0:8]]\n","\n","Labels_test = Testdata['class']\n","Features_test = Testdata[Testdata.columns[0:8]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"in04P8fU8u3f"},"source":["## Scaling"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ee3KXrDc8u3g","colab":{},"executionInfo":{"status":"ok","timestamp":1596812577809,"user_tz":300,"elapsed":629,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}}},"source":["scaler = preprocessing.StandardScaler().fit(Features_train)\n","Features_train_scaler = scaler.transform(Features_train)\n","Features_valid_scaler = scaler.transform(Features_valid)\n","Features_test_scaler = scaler.transform(Features_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j6uUp8t-8u36"},"source":["## Function to print metrics of a model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YAnOtP4S8u37","colab":{},"executionInfo":{"status":"ok","timestamp":1596812580342,"user_tz":300,"elapsed":445,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}}},"source":["def metrics(Y_validation,predictions):\n","    print('Accuracy:', accuracy_score(Y_validation, predictions))\n","    print('F1 score:', f1_score(Y_validation, predictions,average='weighted'))\n","    print('Recall:', recall_score(Y_validation, predictions,average='weighted'))\n","    print('Precision:', precision_score(Y_validation, predictions, average='weighted'))\n","    print('\\n clasification report:\\n', classification_report(Y_validation, predictions))\n","    print('\\n confusion matrix:\\n',confusion_matrix(Y_validation, predictions))\n","    #Creating confussion matrix\n","    snn_cm = confusion_matrix(Y_validation, predictions)\n","\n","    # Plotting cofusion matrix\n","    snn_df_cm = pd.DataFrame(snn_cm, range(6), range(6))  \n","    plt.figure(figsize = (20,14))  \n","    sn.set(font_scale=1.4) #for label size  \n","    sn.heatmap(snn_df_cm, annot=True, annot_kws={\"size\": 12}) # font size  \n","    plt.show()  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-w6S7G8n8u3_"},"source":["## Tuning KNN model, n_neighbors parameter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YNXp-ojn8u4A","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1595433129700,"user_tz":300,"elapsed":3718079,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"f99d66c1-891f-4400-e297-bc9094e48fb8"},"source":["#Testing different values of n_neighbors\n","limit=6\n","x=[x for x in range(1,limit)]\n","yValidation=[0 for x in range(1,limit)]\n","ytrain=[0 for x in range(1,limit)]\n","yValidationScaler=[0 for x in range(1,limit)]\n","ytrainScaler=[0 for x in range(1,limit)]\n","yValidationPCA=[0 for x in range(1,limit)]\n","ytrainPCA=[0 for x in range(1,limit)]\n","yValidationPCAScaler=[0 for x in range(1,limit)]\n","ytrainPCAScaler=[0 for x in range(1,limit)]\n","for i in range(1,limit):\n","    KNN = KNeighborsClassifier(n_neighbors=i)\n","    \n","    KNN.fit(Features_train, Labels_train)\n","    trainScore=KNN.score(Features_train,Labels_train)\n","    validationScore=KNN.score(Features_valid,Labels_valid)\n","    \n","    KNN.fit(Features_train_scaler, Labels_train)\n","    trainScoreScaler=KNN.score(Features_train_scaler,Labels_train)\n","    validationScoreScaler=KNN.score(Features_valid_scaler,Labels_valid)\n","    \n","    print('n-neighbors value:',i)\n","    ytrain[i-1]=trainScore   \n","    yValidation[i-1]=validationScore\n","    \n","    ytrainScaler[i-1]=trainScoreScaler   \n","    yValidationScaler[i-1]=validationScoreScaler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gagzTZ0i8u4D"},"source":["## Plotting n_neighbors vs accuracy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hlLIxgiQ8u4E","colab":{"base_uri":"https://localhost:8080/","height":764},"executionInfo":{"status":"ok","timestamp":1595433314713,"user_tz":300,"elapsed":1307,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"46fa53fb-d904-4a09-de59-de6076067efc"},"source":["plt.figure(figsize=(12, 8), dpi=100, facecolor='w', edgecolor='k')\n","plt.plot(x,ytrain,label='Train')\n","plt.plot(x,yValidation,label='Validation')\n","plt.plot(x,ytrainScaler,label='Train-Scaling')\n","plt.plot(x,yValidationScaler,label='Validation-Scaling')\n","\n","plt.xlabel('n-neighbors')\n","plt.ylabel('Accuracy')\n","plt.title('n-neighbors vs Accuracy')\n","plt.legend()\n","plt.xticks(range(1,6))\n","plt.savefig('KNN-Algorithm.pdf', dpi=300)\n","plt.show()  \n","print('The best score with data validation: ', max(yValidation),'with Neighbors: ',x[yValidation.index(max(yValidation))])\n","print('The best score with data validation with Scaling: ', max(yValidationScaler),'with Neighbors: ',x[yValidationScaler.index(max(yValidationScaler))])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AxzXxV1n8u4I"},"source":["## KNN model with best n_neighbors value"]},{"cell_type":"code","metadata":{"id":"iOlLYWPZ_hpb","colab_type":"code","colab":{}},"source":["Features_train_valid = np.concatenate((Features_train, Features_valid), axis=0)\n","Labels_train_valid = np.concatenate((Labels_train, Labels_valid), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4vSi2F6Z8u4R","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595445028476,"user_tz":300,"elapsed":12903,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"9c7da355-bca3-42b6-dea2-6e26bc991f1d"},"source":["KNN = KNeighborsClassifier(n_neighbors=x[yValidation.index(max(yValidation))])\n","KNN.fit(Features_train_valid, Labels_train_valid)\n","predictions = KNN.predict(Features_test)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NmiCy00f8u43"},"source":["## Tuning logistic regression model, C parameter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TAUtasAW8u44","colab":{}},"source":["#Testing different values of C\n","limit=1\n","step=0.1\n","x=[0 for x in range(0,int(limit/step))]\n","yValidation=[0 for x in range(0,int(limit/step))]\n","ytrain=[0 for x in range(0,int(limit/step))]\n","yValidationScaler=[0 for x in range(0,int(limit/step))]\n","ytrainScaler=[0 for x in range(0,int(limit/step))]\n","yValidationPCA=[0 for x in range(0,int(limit/step))]\n","ytrainPCA=[0 for x in range(0,int(limit/step))]\n","yValidationPCAScaler=[0 for x in range(0,int(limit/step))]\n","ytrainPCAScaler=[0 for x in range(0,int(limit/step))]\n","i=step\n","index=0\n","while i<limit:\n","    lr = LogisticRegression(C=i)\n","    \n","    lr.fit(Features_train, Labels_train)\n","    trainScore=lr.score(Features_train,Labels_train)\n","    validationScore=lr.score(Features_valid,Labels_valid)\n","    \n","    lr.fit(Features_train_scaler, Labels_train)\n","    trainScoreScaler=lr.score(Features_train_scaler,Labels_train)\n","    validationScoreScaler=lr.score(Features_valid_scaler,Labels_valid)\n","\n","    ytrain[index]=trainScore   \n","    yValidation[index]=validationScore\n","    \n","    ytrainScaler[index]=trainScoreScaler   \n","    yValidationScaler[index]=validationScoreScaler\n","    \n","    print('C value:',i)\n","    \n","    x[index]=i\n","    i+=step\n","    index+=1 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NtE3KhHA8u48"},"source":["## Plotting C vs accuracy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7tQwgEAt8u49","scrolled":true,"colab":{}},"source":["plt.figure(figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n","plt.plot(x,ytrain,'o-',label='Train')\n","plt.plot(x,yValidation,'v-',label='Validation')\n","plt.plot(x,ytrainScaler,'s-',label='Train-Scaling')\n","plt.plot(x,yValidationScaler,'*-',label='Validation-Scaling')\n","\n","plt.xlabel('C')\n","plt.ylabel('Accuracy')\n","plt.title('C vs Accuracy')\n","plt.legend()\n","plt.savefig('LR-Algorithm.pdf', dpi=300)\n","plt.show()  \n","print('The best score with data validation: ', max(yValidation),'with C: ',x[yValidation.index(max(yValidation))])\n","print('The best score with data validation with Scaling: ', max(yValidationScaler),'with C: ',x[yValidationScaler.index(max(yValidationScaler))])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SWwJsgHR8u5A"},"source":["## Logistic regression model with the best C value"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xnuHg-NBRIdP","colab":{}},"source":["Features_train_valid = np.concatenate((Features_train_scaler, Features_valid_scaler), axis=0)\n","Labels_train_valid = np.concatenate((Labels_train, Labels_valid), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yGvg_RQE8u5B","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595433892178,"user_tz":300,"elapsed":9006,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"bacd9920-7466-4d76-922b-aa04e5509403"},"source":["lr = LogisticRegression(C=x[yValidationScaler.index(max(yValidationScaler))])\n","lr.fit(Features_train_valid, Labels_train_valid)\n","predictions = lr.predict(Features_test_scaler)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Kyg1Gw3r8u5I"},"source":["## Gaussian Naive Bayes model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"B7RcaCH28u5J","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593202415154,"user_tz":300,"elapsed":9488,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"2f30b7ff-0ef4-4038-d7b7-83585142761a"},"source":["NB = GaussianNB()\n","\n","NB.fit(Features_train, Labels_train)\n","predictions = NB.predict(Features_test)\n","metrics(Labels_test,predictions)\n","\n","NB.fit(Features_train_scaler, Labels_train)\n","predictions = NB.predict(Features_test_scaler)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"18JrDJ618u5N"},"source":["## Tuning MLP model, value of hidden_layer_sizes parameter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r__SJOC48u5O","scrolled":true,"colab":{}},"source":["limit=1200\n","step=200\n","x=[x for x in range(0,int(limit/step)-1)]\n","yValidation=[0 for x in range(0,int(limit/step)-1)]\n","ytrain=[0 for x in range(0,int(limit/step)-1)]\n","yValidationScaler=[0 for x in range(0,int(limit/step)-1)]\n","ytrainScaler=[0 for x in range(0,int(limit/step)-1)]\n","yValidationPCA=[0 for x in range(0,int(limit/step)-1)]\n","ytrainPCA=[0 for x in range(0,int(limit/step)-1)]\n","yValidationPCAScaler=[0 for x in range(0,int(limit/step)-1)]\n","ytrainPCAScaler=[0 for x in range(0,int(limit/step)-1)]\n","i=step\n","index=0\n","while i<limit:\n","    MLP = MLPClassifier(solver='adam', alpha=.5, hidden_layer_sizes=(i))\n","    MLP.fit(Features_train, Labels_train)\n","    trainScore=MLP.score(Features_train,Labels_train)\n","    validationScore=MLP.score(Features_valid,Labels_valid)\n","    \n","    MLP.fit(Features_train_scaler, Labels_train)\n","    trainScoreScaler=MLP.score(Features_train_scaler,Labels_train)\n","    validationScoreScaler=MLP.score(Features_valid_scaler,Labels_valid)\n"," \n","    ytrain[index]=trainScore   \n","    yValidation[index]=validationScore\n","    \n","    ytrainScaler[index]=trainScoreScaler   \n","    yValidationScaler[index]=validationScoreScaler\n","    \n","    print('hidden_layer_sizes value:',i)\n","    x[index]=i\n","    i+=step\n","    index+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_GUswl288u5S"},"source":["## Plotting neurons vs Accuracy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6xLdlXMy8u5T","colab":{}},"source":["plt.figure(figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n","plt.plot(x,ytrain,'o-',label='Train')\n","plt.plot(x,yValidation,'v-',label='Validation')\n","plt.plot(x,ytrainScaler,'s-',label='Train-Scaling')\n","plt.plot(x,yValidationScaler,'*-',label='Validation-Scaling')\n","\n","plt.xlabel('Neurons')\n","plt.ylabel('Accuracy')\n","plt.title('Neurons vs Accuracy')\n","plt.legend()\n","plt.savefig('MLP-Algorithm.pdf', dpi=300)\n","plt.show()  \n","print('The best score with data validation: ', max(yValidation),'with Neurons: ',x[yValidation.index(max(yValidation))])\n","print('The best score with data validation with Scaling: ', max(yValidationScaler),'with Neurons: ',x[yValidationScaler.index(max(yValidationScaler))])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LyjimEh68u5Y"},"source":["## MLP model with best value of hidden_layer_sizes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qWJ9GsuK8u5Y","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593203733925,"user_tz":300,"elapsed":1309470,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"9e1233b0-31bb-422f-cd43-861433c1d824"},"source":["MLP = MLPClassifier(solver='adam', alpha=.5, hidden_layer_sizes=x[yValidationScaler.index(max(yValidationScaler))])\n","MLP.fit(Features_train_scaler, Labels_train)\n","predictions = MLP.predict(Features_test_scaler)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-9QnNR4X8u5b"},"source":["## Tuning Random forest model, n_estimators parameter"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WDfK0i4d8u5c","colab":{}},"source":["#Testing different quantities of neighbors\n","limit=100\n","step=10\n","x=[x for x in range(1,limit,10)]\n","yValidation=[0 for x in range(1,limit,10)]\n","ytrain=[0 for x in range(1,limit,10)]\n","yValidationScaler=[0 for x in range(1,limit,10)]\n","ytrainScaler=[0 for x in range(1,limit,10)]\n","yValidationPCA=[0 for x in range(1,limit,10)]\n","ytrainPCA=[0 for x in range(1,limit,10)]\n","yValidationPCAScaler=[0 for x in range(1,limit,10)]\n","ytrainPCAScaler=[0 for x in range(1,limit,10)]\n","index=0\n","for i in range(1,limit,10):\n","    RF = RandomForestClassifier(n_estimators=i)\n","    \n","    RF.fit(Features_train, Labels_train)\n","    trainScore=RF.score(Features_train, Labels_train)\n","    validationScore=RF.score(Features_valid, Labels_valid)\n","    \n","    RF.fit(Features_train_scaler, Labels_train)\n","    trainScoreScaler=RF.score(Features_train_scaler, Labels_train)\n","    validationScoreScaler=RF.score(Features_valid_scaler, Labels_valid)\n","    \n","    print('n_estimators value:',i)\n","    ytrain[index]=trainScore   \n","    yValidation[index]=validationScore\n","    \n","    ytrainScaler[index]=trainScoreScaler   \n","    yValidationScaler[index]=validationScoreScaler\n","    \n","    index+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"p5K7oaw-8u5t"},"source":["## Plotting n_estimators vs accuracy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pVNpQ1dT8u5u","colab":{}},"source":["plt.figure(figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n","plt.plot(x,ytrain,label='Train')\n","plt.plot(x,yValidation,label='Validation')\n","plt.plot(x,ytrainScaler,label='Train-Scaling')\n","plt.plot(x,yValidationScaler,label='Validation-Scaling')\n","\n","plt.xlabel('n-estimators')\n","plt.ylabel('Accuracy')\n","plt.title('n-estimators vs Accuracy')\n","plt.legend(fontsize=10)\n","plt.savefig('RF-Algorithm.pdf', dpi=300)\n","plt.show()  \n","print('The best score with data validation: ', max(yValidation),'with estimators: ',x[yValidation.index(max(yValidation))])\n","print('The best score with data validation with Scaling: ', max(yValidationScaler),'with estimators: ',x[yValidationScaler.index(max(yValidationScaler))])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dhKsEzp68u59"},"source":["## Random Forest model with best n_estimators value"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dAcHtEs3RZjj","colab":{}},"source":["Features_train_valid = np.concatenate((Features_train_scaler, Features_valid_scaler), axis=0)\n","Labels_train_valid = np.concatenate((Labels_train, Labels_valid), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XMPnQJPz8u5-","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595434479378,"user_tz":300,"elapsed":550304,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"f06664b0-0c0b-4f1d-9019-c7af90a7cb40"},"source":["RF = RandomForestClassifier(n_estimators=x[yValidationScaler.index(max(yValidationScaler))])\n","RF.fit(Features_train_valid, Labels_train_valid)\n","predictions = RF.predict(Features_test_scaler)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V2omIiWc8u6Y"},"source":["## Decision Tree model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"emN6lMHz8u6Z","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593220087641,"user_tz":300,"elapsed":41210,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"c024c9c2-57e2-4afa-f3e7-625e2ccdea88"},"source":["DT = DecisionTreeClassifier()\n","DT.fit(Features_train_scaler, Labels_train)\n","predictions = DT.predict(Features_test_scaler)\n","metrics(Labels_test,predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eUuBf8we8u6e"},"source":["## Cross validation of all models "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"go5DWQWe_-VR","colab":{}},"source":["def fold_creation(filenames, index):\n","    filenames_fold=[]\n","    filenames_fold.append(filenames[index[0]])\n","    filenames_fold.append(filenames[index[0]+1])\n","    filenames_fold.append(filenames[index[1]])\n","    filenames_fold.append(filenames[index[1]+1])\n","    filenames_fold.append(filenames[index[2]])\n","    filenames_fold.append(filenames[index[2]+1])\n","    filenames_fold.append(filenames[index[3]])\n","    filenames_fold.append(filenames[index[3]+1])\n","\n","    [df1,df2,df3,df4,df5,df6]=Data_separation(filenames_fold[0])\n","    Gesto1=df1\n","    Gesto2=df2\n","    Gesto3=df3\n","    Gesto4=df4\n","    Gesto5=df5\n","    Gesto6=df6\n","\n","    for i in range(len(filenames_fold[1:])):\n","        [df1,df2,df3,df4,df5,df6]=Data_separation(filenames[i])\n","        Gesto1=Gesto1.append(df1)\n","        Gesto2=Gesto2.append(df2)\n","        Gesto3=Gesto3.append(df3)\n","        Gesto4=Gesto4.append(df4)\n","        Gesto5=Gesto5.append(df5)\n","        Gesto6=Gesto6.append(df6)\n","\n","    fold=Gesto1\n","    fold=fold.append(Gesto2)\n","    fold=fold.append(Gesto3)\n","    fold=fold.append(Gesto4)\n","    fold=fold.append(Gesto5)\n","    fold=fold.append(Gesto6)\n","    return fold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HnqaLmsSFkU7","colab":{}},"source":["pacientes = []\n","for i in range(0, 72, 2):\n","    pacientes.append(i)\n","index=np.random.choice(pacientes, (9, 4), replace=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4acLf0BAFk07","colab":{}},"source":["fold0=fold_creation(filenames, index[0])\n","fold1=fold_creation(filenames, index[1])\n","fold2=fold_creation(filenames, index[2])\n","fold3=fold_creation(filenames, index[3])\n","fold4=fold_creation(filenames, index[4])\n","fold5=fold_creation(filenames, index[5])\n","fold6=fold_creation(filenames, index[6])\n","fold7=fold_creation(filenames, index[7])\n","fold8=fold_creation(filenames, index[8])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bHx9WfEJIzPN","colab":{}},"source":["Labels_0 = fold0['class']\n","Features_0 = fold0[fold0.columns[0:8]]\n","\n","Labels_1 = fold1['class']\n","Features_1 = fold1[fold1.columns[0:8]]\n","\n","Labels_2 = fold2['class']\n","Features_2 = fold2[fold2.columns[0:8]]\n","\n","Labels_3 = fold3['class']\n","Features_3 = fold3[fold3.columns[0:8]]\n","\n","Labels_4 = fold4['class']\n","Features_4 = fold4[fold4.columns[0:8]]\n","\n","Labels_5 = fold5['class']\n","Features_5 = fold5[fold5.columns[0:8]]\n","\n","Labels_6 = fold6['class']\n","Features_6 = fold6[fold6.columns[0:8]]\n","\n","Labels_7 = fold7['class']\n","Features_7 = fold7[fold7.columns[0:8]]\n","\n","Labels_8 = fold8['class']\n","Features_8 = fold8[fold8.columns[0:8]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nT4nblYmIzPZ","colab":{}},"source":["Features_full = Features_0.append(Features_1)\n","Features_full = Features_full.append(Features_2)\n","Features_full = Features_full.append(Features_3)\n","Features_full = Features_full.append(Features_4)\n","Features_full = Features_full.append(Features_5)\n","Features_full = Features_full.append(Features_6)\n","Features_full = Features_full.append(Features_7)\n","Features_full = Features_full.append(Features_8)\n","\n","scaler = preprocessing.StandardScaler().fit(Features_full)\n","Features_fold0 = scaler.transform(Features_0)\n","Features_fold1 = scaler.transform(Features_1)\n","Features_fold2 = scaler.transform(Features_2)\n","Features_fold3 = scaler.transform(Features_3)\n","Features_fold4 = scaler.transform(Features_4)\n","Features_fold5 = scaler.transform(Features_5)\n","Features_fold6 = scaler.transform(Features_6)\n","Features_fold7 = scaler.transform(Features_7)\n","Features_fold8 = scaler.transform(Features_8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cUXzD8SaIzPe","colab":{}},"source":["folds = [Features_fold0, Features_fold1, Features_fold2, Features_fold3, Features_fold4, Features_fold5, Features_fold6, Features_fold7, Features_fold8]\n","labels = [Labels_0, Labels_1, Labels_2, Labels_3, Labels_4, Labels_5, Labels_6, Labels_7, Labels_8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BC-oWkOEIzPh","colab":{}},"source":["def manual_cross_val(model, folds, labels):\n","    Results = []\n","    index_t = [[0, 1, 2, 3, 4, 5, 6, 7], [8, 0, 1, 2, 3, 4, 5, 6], [7, 8, 0, 1, 2, 3, 4, 5], [6, 7, 8, 0, 1, 2, 3, 4], [5, 6, 7, 8, 0, 1, 2, 3]\n","            , [4, 5, 6, 7, 8, 0, 1, 2], [3, 4, 5, 6, 7, 8, 0, 1], [2, 3, 4, 5, 6, 7, 8, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n","    index_v = [8, 7, 6, 5, 4, 3 , 2, 1, 0]\n","    for i in range(len(index_t)):\n","      Train = folds[index_t[i][0]]\n","      Trainlabels = labels[index_t[i][0]]\n","      for j in range(len(index_t[i][1:])):\n","          Train = np.append(Train, folds[index_t[i][j]], axis=0)\n","          Trainlabels = np.append(Trainlabels, labels[index_t[i][j]], axis=0)\n","      Valid = folds[index_v[i]]\n","      Validlabels = labels[index_v[i]]\n","      model.fit(Train, Trainlabels)\n","      pred = model.predict(Valid)\n","      Results.append(accuracy_score(Validlabels, pred))\n","    return [np.mean(Results), np.std(Results)]\n","\n","KNN = KNeighborsClassifier(n_neighbors=1)\n","lr = LogisticRegression(C=0.3)\n","NB = GaussianNB()\n","MLP = MLPClassifier(solver='adam', alpha=.5, hidden_layer_sizes=800)\n","RF = RandomForestClassifier(n_estimators=71)\n","DT = DecisionTreeClassifier()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dwDc08g-I_IR","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1595891196593,"user_tz":300,"elapsed":11738876,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"3de77516-1f52-4256-d13f-a4530fbae0a1"},"source":["R_KNN = manual_cross_val(KNN, folds, labels)\n","print('KNN: ', R_KNN[0], R_KNN[1])\n","R_lr = manual_cross_val(lr, folds, labels)\n","print('LR: ', R_lr[0], R_lr[1])\n","R_NB = manual_cross_val(NB, folds, labels)\n","print('NB: ', R_NB[0], R_NB[1])\n","R_MLP = manual_cross_val(MLP, folds, labels)\n","print('MLP: ', R_MLP[0], R_MLP[1])\n","R_RF = manual_cross_val(RF, folds, labels)\n","print('RF: ', R_RF[0], R_RF[1])\n","R_DT = manual_cross_val(DT, folds, labels)\n","print('DT: ', R_DT[0], R_DT[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WT9O2cRg8u6h"},"source":["# Deep Learning using KERAS"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"00wHfcn98u6i"},"source":["## Tuning FNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ngEn7S2g8u6j","colab":{}},"source":["encoder = LabelEncoder()\n","encoder.fit(Labels_train)\n","encoded_YTrain = encoder.transform(Labels_train)\n","encoded_YValidation = encoder.transform(Labels_valid)\n","encoded_YTest = encoder.transform(Labels_test)\n","encode_XTrain=Features_train_scaler\n","encode_Xvalidation=Features_valid_scaler\n","encode_Xtest=Features_test_scaler\n","# Convert integers to one hot labels\n","categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","categorical_YTest = np_utils.to_categorical(encoded_YTest)\n","\n","# Function to create model, required for KerasClassifier\n","def create_model():\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(1000, input_dim=encode_XTrain.shape[1], activation='relu'))\n","    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(6, activation='softmax'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CRlFGfsF8u6p","scrolled":true,"colab":{}},"source":["# How to Tune Batch Size and Number of Epochs\n","\n","model = KerasClassifier(build_fn=create_model, verbose=1)\n","# define the grid search parameters\n","batch_size = [50000, 100000,150000]\n","epochs = [150, 170, 200]\n","param_grid = dict(batch_size=batch_size, epochs=epochs)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=3)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yxL-b3kZ8u6s","scrolled":true,"colab":{}},"source":["# How to Tune the Training Optimization Algorithm\n","\n","# Function to create model, required for KerasClassifier\n","def create_model(optimizer='adam'):\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(1000, input_dim=encode_XTrain.shape[1], activation='relu'))\n","    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(1000, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(6, activation='softmax'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=300, batch_size=50000, verbose=1)\n","# define the grid search parameters\n","optimizer = ['RMSprop','Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n","param_grid = dict(optimizer=optimizer)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MCYR2hDE8u6y","colab":{}},"source":["# How to Tune Network Weight Initialization\n","\n","def create_model(init_mode='uniform'):\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(1000,kernel_initializer=init_mode, input_dim=encode_XTrain.shape[1], activation='relu'))\n","    model.add(Dense(1000, kernel_initializer=init_mode, activation='relu'))\n","    model.add(Dense(1000, kernel_initializer=init_mode, activation='relu'))\n","    model.add(Dense(6, kernel_initializer=init_mode, activation='softmax'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=300, batch_size=50000, verbose=1)\n","init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n","param_grid = dict(init_mode=init_mode)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Huot6XRO8u63","colab":{}},"source":["# How to Tune the Neuron Activation Function\n","\n","def create_model(activation='relu'):\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(1000,kernel_initializer='he_normal', input_dim=encode_XTrain.shape[1], activation=activation))\n","    model.add(Dense(1000, kernel_initializer='he_normal', activation=activation))\n","    model.add(Dense(1000, kernel_initializer='he_normal', activation=activation))\n","    model.add(Dense(6, kernel_initializer='he_normal', activation='softmax'))\n","    optimizer = SGD(lr=0.2, momentum=0)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=300, batch_size=50000, verbose=1)\n","# define the grid search parameters\n","activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n","param_grid = dict(activation=activation)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LoxpiGMo8u68","colab":{}},"source":["# How to Tune the Number of Neurons in the Hidden Layer\n","\n","from keras.layers import Dropout\n","from keras.constraints import maxnorm\n","\n","def create_model(neurons=1):\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(neurons,kernel_initializer='glorot_normal', input_dim=encode_XTrain.shape[1], activation='relu'))\n","    model.add(Dense(neurons, kernel_initializer='glorot_normal', activation='relu'))\n","    model.add(Dense(neurons, kernel_initializer='glorot_normal', activation='relu'))\n","    model.add(Dense(6, kernel_initializer='glorot_normal', activation='softmax'))\n","    optimizer = SGD(lr=0.2, momentum=0)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=300, batch_size=50000, verbose=1)\n","# define the grid search parameters\n","neurons = [850, 900, 950, 1000, 1050, 1100, 1200]\n","param_grid = dict(neurons=neurons)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=3)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6No0NC9Y8u6-"},"source":["## Cross validation on ANN with best parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OJFAB_1rftcH","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1595980144167,"user_tz":300,"elapsed":11520062,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"b1e7a0df-4902-4a65-ca2a-2486beacd48c"},"source":["def manual_cross_val_ANN(folds, labels):\n","    Results = []\n","    index_t = [[0, 1, 2, 3, 4, 5, 6, 7], [8, 0, 1, 2, 3, 4, 5, 6], [7, 8, 0, 1, 2, 3, 4, 5], [6, 7, 8, 0, 1, 2, 3, 4], [5, 6, 7, 8, 0, 1, 2, 3]\n","            , [4, 5, 6, 7, 8, 0, 1, 2], [3, 4, 5, 6, 7, 8, 0, 1], [2, 3, 4, 5, 6, 7, 8, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n","    index_v = [8, 7, 6, 5, 4, 3 , 2, 1, 0]\n","    for i in range(len(index_t)):\n","      encoder = LabelEncoder()\n","      Train = folds[index_t[i][0]]\n","      Trainlabels = labels[index_t[i][0]]\n","      for j in range(len(index_t[i][1:])):\n","          Train = np.append(Train, folds[index_t[i][j]], axis=0)\n","          Trainlabels = np.append(Trainlabels, labels[index_t[i][j]], axis=0)\n","      Valid = folds[index_v[i]]\n","      Validlabels = labels[index_v[i]]\n","      encoder.fit(Trainlabels)\n","      encoded_YTrain = encoder.transform(Trainlabels)\n","      encoded_YValidation = encoder.transform(Validlabels)\n","      encode_XTrain=Train #.reshape(Train.shape[0],Train.shape[1],1)\n","      encode_Xvalidation=Valid #.reshape(Valid.shape[0],Valid.shape[1],1)\n","      categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","      categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","\n","      visible = Input(shape=(encode_XTrain.shape[1],))\n","      hidden1 = Dense(1050, kernel_initializer='normal', activation='tanh')(visible)\n","      hidden2 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden1)\n","      hidden3 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden2)\n","      hidden4 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden3)\n","      output = Dense(6, kernel_initializer='normal', activation='softmax')(hidden4)\n","      model = Model(inputs=visible, outputs=output)\n","      # Compile model\n","      model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Nadam(lr=0.01), metrics=['accuracy'])\n","      model.fit(encode_XTrain, categorical_YTrain, epochs=150, batch_size=50000,verbose=0)\n","      snn_pred = model.predict(encode_Xvalidation, batch_size=50000, verbose=1)  \n","      snn_pred_lab = np.argmax(snn_pred, axis=1)\n","      snn_real_lab = np.argmax(categorical_YValidation, axis=1)\n","      Results.append(accuracy_score(snn_real_lab, snn_pred_lab))\n","    return [np.mean(Results), np.std(Results)]\n","\n","R_ANN = manual_cross_val_ANN(folds, labels)\n","print('ANN: ', R_ANN[0], R_ANN[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uM05Eyj-8u7D"},"source":["## Training and testing FNN\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j3SXGfH48u7E","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596822496793,"user_tz":300,"elapsed":1880788,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"39b180e9-25e5-477f-f5e6-c05546d80265"},"source":["encoder = LabelEncoder()\n","encoder.fit(Labels_train)\n","encoded_YTrain = encoder.transform(Labels_train)\n","encoded_YValidation = encoder.transform(Labels_valid)\n","encoded_YTest = encoder.transform(Labels_test)\n","encode_XTrain=Features_train_scaler\n","encode_Xvalidation=Features_valid_scaler\n","encode_Xtest=Features_test_scaler\n","# Convert integers to one hot labels\n","categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","categorical_YTest = np_utils.to_categorical(encoded_YTest)\n","\n","visible = Input(shape=(encode_XTrain.shape[1],))\n","hidden1 = Dense(1050, kernel_initializer='normal', activation='tanh')(visible)\n","hidden2 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden1)\n","hidden3 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden2)\n","hidden4 = Dense(1050, kernel_initializer='normal', activation='tanh')(hidden3)\n","output = Dense(6, kernel_initializer='normal', activation='softmax')(hidden4)\n","model = Model(inputs=visible, outputs=output)\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Nadam(lr=0.01), metrics=['accuracy'])\n","# summarize layers\n","print(model.summary())\n","# Fit the model\n","history1=model.fit(encode_XTrain, categorical_YTrain, epochs=120, batch_size=50000, validation_data=(encode_Xvalidation, categorical_YValidation))\n","\n","with plt.style.context('seaborn-white'):\n","  # plot metrics\n","  plt.plot(history1.history['accuracy'])\n","  plt.plot(history1.history['val_accuracy'])\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Accuracy')\n","  plt.title('Model Accuracy')\n","  plt.legend(['train', 'validation'], loc='upper left', fontsize=10)\n","  plt.grid(True)\n","  plt.savefig('ACC_ANN.pdf', dpi=300)\n","  plt.show()\n","\n","  plt.plot(history1.history['loss'])\n","  plt.plot(history1.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'validation'], loc='upper left', fontsize=10)\n","  plt.grid(True)\n","  plt.savefig('LOSS_ANN.pdf', dpi=300)\n","  plt.show()\n","\n","scores = model.evaluate(encode_Xtest, categorical_YTest, verbose=0)\n","print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xYipKo7l8u7J","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596814588840,"user_tz":300,"elapsed":2242,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"1ca96c43-14e1-4afb-c092-0fc81efd27b3"},"source":["snn_pred = model.predict(encode_Xtest, batch_size=50000, verbose=1)  \n","snn_predicted = np.argmax(snn_pred, axis=1)\n","snn_pred_lab = np.argmax(snn_pred, axis=1)\n","snn_real_lab = np.argmax(categorical_YTest, axis=1)\n","metrics(snn_real_lab,snn_pred_lab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"O6CTTgzl8u7O"},"source":["## Tuning CNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ItpYZQon8u7P","colab":{}},"source":["encoder = LabelEncoder()\n","encoder.fit(Labels_train)\n","encoded_YTrain = encoder.transform(Labels_train)\n","encoded_YValidation = encoder.transform(Labels_valid)\n","encoded_YTest = encoder.transform(Labels_test)\n","encode_XTrain=Features_train_scaler.reshape(Features_train_scaler.shape[0],Features_train_scaler.shape[1],1)\n","encode_Xvalidation=Features_valid_scaler.reshape(Features_valid_scaler.shape[0],Features_valid_scaler.shape[1],1)\n","encode_Xtest=Features_test_scaler.reshape(Features_test_scaler.shape[0],Features_test_scaler.shape[1],1)\n","# Convert integers to one hot labels\n","categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","categorical_YTest = np_utils.to_categorical(encoded_YTest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mN9_hdlE8u7U","colab":{}},"source":["# How to Tune the Training Optimization Algorithm\n","\n","# Function to create model, required for KerasClassifier\n","def create_model(optimizer='adam'):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=200, batch_size=15000, verbose=1)\n","# define the grid search parameters\n","optimizer = ['RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n","param_grid = dict(optimizer=optimizer)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GHQFGOx48u7W","colab":{}},"source":["# How to Tune Learning Rate and Momentum\n","def create_model(learn_rate=0.01, momentum=0):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu'))\n","    model.add(MaxPooling1D(1))\n","    model.add(Conv1D(filters=32, kernel_size=(3), activation='relu'))\n","    model.add(Flatten())\n","    model.add(Dense(100, activation='softsign'))\n","    model.add(Dense(6,activation='softmax'))\n","    # Compile model\n","    optimizer = SGD(lr=learn_rate, momentum=momentum)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=1)\n","# define the grid search parameters\n","learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n","momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n","param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YXcWxug_8u7R","colab":{}},"source":["# Function to create model, required for KerasClassifier\n","def create_model():\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","# How to Tune Batch Size and Number of Epochs\n","\n","model = KerasClassifier(build_fn=create_model, epochs=150, verbose=1)\n","# define the grid search parameters\n","batch_size = [10000, 15000, 20000, 30000, 50000]\n","param_grid = dict(batch_size=batch_size)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZKinYgGK8u7Z","colab":{}},"source":["# How to Tune Network Weight Initialization\n","\n","def create_model(init_mode='uniform'):\n","    # create model\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(1050, activation='relu', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10000, verbose=1)\n","init_mode = ['uniform', 'normal', 'glorot_normal', 'he_normal']\n","param_grid = dict(init_mode=init_mode)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qv-HW4_I8u7b","colab":{}},"source":["# How to Tune the Neuron Activation Function\n","\n","def create_model(activation='relu'):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1050, activation=activation, kernel_initializer='normal'))\n","    model.add(Dense(1050, activation=activation, kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10000, verbose=1)\n","# define the grid search parameters\n","activation = ['relu', 'tanh', 'linear']\n","param_grid = dict(activation=activation)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ewiDjxGV8u7f","colab":{}},"source":["# How to Tune Dropout Regularization\n","def create_model(dropout_rate=0.0, weight_constraint=0):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1050, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(1050, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10000, verbose=1)\n","# define the grid search parameters\n","weight_constraint = [1, 2, 3, 4, 5]\n","dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n","param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ElNlrsLH8u7l","colab":{}},"source":["# How to Tune the Number of Neurons in the Hidden Layer\n","def create_model(neurons=1050):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=32, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(neurons, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(neurons, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10000, verbose=1)\n","# define the grid search parameters\n","neurons = [1050, 1100, 1200, 1300]\n","param_grid = dict(neurons=neurons)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yb83obqBuKRl","colab":{}},"source":["# How to Tune the Number of filters \n","def create_model(filters=32, kernel_size=3):\n","    # create model\n","    model = Sequential()\n","    model.add(Conv1D(filters=filters, kernel_size=kernel_size,kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","    model.add(Conv1D(filters=filters, kernel_size=kernel_size,kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","    model.add(keras.layers.Activation('relu'))\n","    #model.add(MaxPooling1D(pool_size=3))\n","    model.add(Flatten())\n","    model.add(Dense(1300, activation='tanh', kernel_initializer='normal', kernel_regularizer=keras.regularizers.l2(0.001)))\n","    model.add(Dense(1300, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(600, activation='tanh', kernel_initializer='normal'))\n","    model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","    optimizer = keras.optimizers.Nadam(lr=0.001)\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10000, verbose=0)\n","# define the grid search parameters\n","filters = [16, 32, 64, 128]\n","kernel_size = [1, 2, 3]\n","param_grid = dict(filters=filters, kernel_size=kernel_size)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=2)\n","grid_result = grid.fit(encode_XTrain, categorical_YTrain)\n","# summarize results\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GzxXkFIVOprm","colab_type":"text"},"source":["## Cross validation on CNN with best parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DLECOPUjftb-","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1595967902702,"user_tz":300,"elapsed":11424432,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"2930b2c6-21ba-44f6-d3aa-0f8901d8dac4"},"source":["from sklearn.metrics import accuracy_score\n","\n","def manual_cross_val_CNN(folds, labels):\n","    Results = []\n","    index_t = [[0, 1, 2, 3, 4, 5, 6, 7], [8, 0, 1, 2, 3, 4, 5, 6], [7, 8, 0, 1, 2, 3, 4, 5], [6, 7, 8, 0, 1, 2, 3, 4], [5, 6, 7, 8, 0, 1, 2, 3]\n","            , [4, 5, 6, 7, 8, 0, 1, 2], [3, 4, 5, 6, 7, 8, 0, 1], [2, 3, 4, 5, 6, 7, 8, 0], [1, 2, 3, 4, 5, 6, 7, 8]]\n","    index_v = [8, 7, 6, 5, 4, 3 , 2, 1, 0]\n","    for i in range(len(index_t)):\n","      encoder = LabelEncoder()\n","      Train = folds[index_t[i][0]]\n","      Trainlabels = labels[index_t[i][0]]\n","      for j in range(len(index_t[i][1:])):\n","          Train = np.append(Train, folds[index_t[i][j]], axis=0)\n","          Trainlabels = np.append(Trainlabels, labels[index_t[i][j]], axis=0)\n","      Valid = folds[index_v[i]]\n","      Validlabels = labels[index_v[i]]\n","      encoder.fit(Trainlabels)\n","      encoded_YTrain = encoder.transform(Trainlabels)\n","      encoded_YValidation = encoder.transform(Validlabels)\n","      encode_XTrain=Train.reshape(Train.shape[0],Train.shape[1],1)\n","      encode_Xvalidation=Valid.reshape(Valid.shape[0],Valid.shape[1],1)\n","      categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","      categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","\n","      CNN = Sequential()\n","      CNN.add(Conv1D(filters=128, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","      CNN.add(Conv1D(filters=128, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","      CNN.add(keras.layers.Activation('relu'))\n","      CNN.add(Flatten())\n","      CNN.add(Dense(1300, activation='tanh', kernel_initializer='normal', kernel_regularizer=keras.regularizers.l2(0.001)))\n","      CNN.add(Dense(1300, activation='tanh', kernel_initializer='normal'))\n","      CNN.add(Dense(600, activation='tanh', kernel_initializer='normal'))\n","      CNN.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","      optimizer = keras.optimizers.Nadam(lr=0.001)\n","      # Compile model\n","      CNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","      CNN.fit(encode_XTrain, categorical_YTrain, epochs=100, batch_size=10000, verbose=0)\n","      snn_pred = CNN.predict(encode_Xvalidation, batch_size=10000, verbose=1)  \n","      snn_pred_lab = np.argmax(snn_pred, axis=1)\n","      snn_real_lab = np.argmax(categorical_YValidation, axis=1)\n","      Results.append(accuracy_score(snn_real_lab, snn_pred_lab))\n","    return [np.mean(Results), np.std(Results)]\n","\n","\n","R_CNN = manual_cross_val_CNN(folds, labels)\n","print('CNN: ', R_CNN[0], R_CNN[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g53UopSz8u7n"},"source":["## Training and Testing CNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z_1uh18YDrEl","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596818519856,"user_tz":300,"elapsed":1736680,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"3b7f6ca9-97c7-4588-cd17-7f9bac64b57c"},"source":["encoder = LabelEncoder()\n","encoder.fit(Labels_train)\n","encoded_YTrain = encoder.transform(Labels_train)\n","encoded_YValidation = encoder.transform(Labels_valid)\n","encoded_YTest = encoder.transform(Labels_test)\n","encode_XTrain=Features_train_scaler.reshape(Features_train_scaler.shape[0],Features_train_scaler.shape[1],1)\n","encode_Xvalidation=Features_valid_scaler.reshape(Features_valid_scaler.shape[0],Features_valid_scaler.shape[1],1)\n","encode_Xtest=Features_test_scaler.reshape(Features_test_scaler.shape[0],Features_test_scaler.shape[1],1)\n","# Convert integers to one hot labels\n","categorical_YTrain = np_utils.to_categorical(encoded_YTrain)\n","categorical_YValidation = np_utils.to_categorical(encoded_YValidation)\n","categorical_YTest = np_utils.to_categorical(encoded_YTest)\n","\n","model = Sequential()\n","model.add(Conv1D(filters=128, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear', input_shape=(encode_XTrain.shape[1],1)))\n","model.add(Conv1D(filters=128, kernel_size=(3),kernel_constraint=maxnorm(1), kernel_initializer='normal', activation='linear'))\n","model.add(keras.layers.Activation('relu'))\n","model.add(Flatten())\n","model.add(Dense(1300, activation='tanh', kernel_initializer='normal', kernel_regularizer=keras.regularizers.l2(0.001)))\n","model.add(Dense(1300, activation='tanh', kernel_initializer='normal'))\n","model.add(Dense(600, activation='tanh', kernel_initializer='normal'))\n","model.add(Dense(6,activation='softmax', kernel_initializer='normal'))\n","optimizer = keras.optimizers.Nadam(lr=0.001)\n","# Compile model\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","print(model.summary())\n","\n","history=model.fit(encode_XTrain, categorical_YTrain, epochs=100, batch_size=10000, validation_data=(encode_Xvalidation, categorical_YValidation))\n","\n","with plt.style.context('seaborn-white'):\n","  # plot metrics\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Accuracy')\n","  plt.title('Model Accuracy')\n","  plt.legend(['train', 'validation'], loc='upper left', fontsize=10)\n","  plt.grid(True)\n","  plt.savefig('ACC_CNN.pdf', dpi=300)\n","  plt.show()\n","\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'validation'], loc='upper left', fontsize=10)\n","  plt.grid(True)\n","  plt.savefig('LOSS_CNN.pdf', dpi=300)\n","  plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xYBLG2BHGvlJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596816728340,"user_tz":300,"elapsed":2295,"user":{"displayName":"Alejandro Mora Rubio","photoUrl":"","userId":"07961288293677001436"}},"outputId":"14dbd752-f930-4fb6-f4ec-23a8c89d245d"},"source":["snn_pred = model.predict(encode_Xtest, batch_size=10000, verbose=1)  \n","snn_pred_lab = np.argmax(snn_pred, axis=1)\n","snn_real_lab = np.argmax(categorical_YTest, axis=1)\n","metrics(snn_real_lab, snn_pred_lab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BlWONKXIfXOq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}